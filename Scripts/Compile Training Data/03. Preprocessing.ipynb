{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "---------\n",
    "\n",
    "### Author Information\n",
    "**Author:** PJ Gibson  \n",
    "**Email:** Peter.Gibson@doh.wa.gov  \n",
    "**Github:**   https://github.com/DOH-PJG1303\n",
    "\n",
    "### Project Information\n",
    "**Created Date:** 2023-08-09\n",
    "**Last Updated:** 2023-08-09  \n",
    "**Version:** 1  \n",
    "\n",
    "### Description\n",
    "\n",
    "In this notebook, we'll be applying functions to clean up our dirty data.\n",
    "This step is imperative to record linkage.\n",
    "Note that if you want your model to work properly, you also need to apply this **exact** same step to your applied data.\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "*\\*If you are unfamiliar with the origins of this synthetic data, please see the [Synthetic-Gold](https://github.com/DOH-PJG1303/Synthetic-Gold) github project. We ran the simulation for the state of Nebraska, so all data is relevant to that state.\n",
    "To manage the size of the data we'll have publicly stored on Github, we only captured relevant data for each table for the population living in years 2019-2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Phonetic encoding library\n",
    "import jellyfish\n",
    "\n",
    "# Record linkage specific resources\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.preprocessing import clean, phonetic\n",
    "from recordlinkage.index import Block\n",
    "from recordlinkage.base import BaseCompareFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Data\n",
    "\n",
    "We'll be performing internal deduplication between the dirty data for synthetic Nebraska.\n",
    "This is from the output of the previous script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../Data/Training/02b. Wrangled Dirty Data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Column standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df, mapping_columns, extra_columns=[]):\n",
    "    \"\"\"\n",
    "    Standardizes column names in the DataFrame based on user-provided mapping.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to be processed.\n",
    "    - mapping_columns: Dictionary with keys being existing columns in df \n",
    "                       and values being the standardized names.\n",
    "    - extra_columns: List of column names that should retain their original names.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with standardized column names.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the desired standardized column order\n",
    "    standardized_order = ['fname','mname','lname','dob','sex','add',\n",
    "                          'zip','city','county','state','phone','email']\n",
    "\n",
    "    # Update the dataframe columns based on the provided mapping\n",
    "    df.rename(columns=mapping_columns, inplace=True)\n",
    "\n",
    "    # Ensure that the dataframe columns follow the desired order, \n",
    "    # and then append any extra_columns at the end\n",
    "    all_columns = extra_columns + [col for col in standardized_order if col in df.columns] \n",
    "    \n",
    "    return df[all_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Cleaning\n",
    "\n",
    "| Field       | Preprocessing                                                                                                                                                                      |\n",
    "|-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| fname       | - Convert to lowercase. <br>- Remove non-alphabetical characters. <br>- Generate metaphone representation as `meta_fname`. <br>- Generate soundex representation as `sdx_fname`.     |\n",
    "| lname       | - Convert to lowercase. <br>- Remove non-alphabetical characters. <br>- Generate metaphone representation as `meta_lname`. <br>- Generate soundex representation as `sdx_lname`.     |\n",
    "| mname       | - Convert to lowercase. <br>- Take the first character.                                                                                                                              |\n",
    "| dob         | - Convert to the format 'YYYY-M-D'.                                                                                                                                                    |\n",
    "| sex_at_birth| - Convert to uppercase. <br>- Take the first character. <br>- Replace with NaN if not 'M', 'F', or 'O'.                                                                             |\n",
    "| phone       | - Remove non-digit characters. <br>- Remove leading 0 or 1. <br>- Remove any digit repeated more than 6 times consecutively.                                                        |\n",
    "| email       | - Convert to lowercase. <br>- Remove characters that aren't alphabets, numbers, @, or dots.                                                                                          |\n",
    "| add         | - Convert to lowercase. <br>- Remove characters that aren't alphabets, numbers, or spaces. <br>- Replace common street abbreviations and directions with their respective short forms.|\n",
    "| zip         | - Remove non-digit characters.                                                                                                                                                      |\n",
    "| county      | - Convert to lowercase. <br>- Remove non-alphabetical characters. <br>- Remove the term ' county'.                                                                                   |\n",
    "| city        | - Convert to lowercase. <br>- Remove non-alphabetical characters. <br>- Remove the term ' city'.                                                                                     |\n",
    "| Various Fields | - Replace empty fields or fields with placeholder values (like 'none', 'na', 'missing', 'unknown') with NaN.                                                                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(df):\n",
    "    \"\"\"\n",
    "    Function to apply a series of transformations to a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        The DataFrame to which the transformations should be applied.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The DataFrame after applying the transformations.\n",
    "    \"\"\"\n",
    "    # Lowercase and remove non-alphabetical characters in 'fname' and 'lname'\n",
    "    for field in ['fname', 'lname']:\n",
    "        df[field] = df[field].str.lower().str.replace('[^a-z]','',regex=True)\n",
    "\n",
    "    # Lowercase and take the first character of 'mname'\n",
    "    df['mname'] = df['mname'].str.lower().str.slice(0,1)\n",
    "\n",
    "    # Convert 'dob' column to 'YYYY-M-D' format\n",
    "    df['dob'] = pd.to_datetime(df['dob'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Convert 'sex' to uppercase and take the first letter\n",
    "    df['sex'] = df['sex'].str.upper().str.slice(0, 1)\n",
    "\n",
    "    # Replace any value that isn't 'M', 'F', or 'O' with NaN\n",
    "    df['sex'] = df['sex'].where(df['sex'].isin(['M', 'F', 'O']))\n",
    "\n",
    "    # Remove non-digits from 'phone', remove leading 0 or 1, and remove any digit repeated more than 6 times consecutively\n",
    "    df['phone'] = df['phone'].str.replace('\\D','',regex=True).str.replace('^[01]','',regex=True).str.replace( '.*(\\d)\\\\1{6,}.*', '',regex=True)\n",
    "\n",
    "    # Lowercase and remove non-alphabetical and non-digital characters (excluding @ and .) in 'email'\n",
    "    df['email'] = df['email'].str.lower().str.replace('[^a-z0-9\\.@]','', regex=True)\n",
    "\n",
    "    # Lowercase, remove non-alphabetical and non-digital characters in 'add', and replace common street abbreviations and directions\n",
    "    df['add'] = df['add'].str.lower().str.replace('[^a-z0-9 ]','',regex=True)\n",
    "\n",
    "    replacements = {\n",
    "        'street': 'st',\n",
    "        'avenue': 'ave',\n",
    "        'road': 'rd',\n",
    "        'place': 'pl',\n",
    "        'drive': 'dr',\n",
    "        'court': 'ct',\n",
    "        'lane': 'ln',\n",
    "        'boulevard': 'blvd',\n",
    "        'highway': 'hwy',\n",
    "        'circle': 'cir',\n",
    "        'apartment': 'apt',\n",
    "        'suite': 'ste',\n",
    "        'north': 'n',\n",
    "        'south': 's',\n",
    "        'east': 'e',\n",
    "        'west': 'w',\n",
    "        'northeast':'ne',\n",
    "        'northwest':'nw',\n",
    "        'southeast':'se',\n",
    "        'southwest':'sw',\n",
    "        'terrace': 'ter',\n",
    "        'parkway': 'pkwy',\n",
    "        'alley': 'aly',\n",
    "        'fort': 'ft',\n",
    "        'junction': 'jct',\n",
    "        'point': 'pt',\n",
    "        'square': 'sq',\n",
    "        'heights': 'hts',\n",
    "        'hollow': 'holw',\n",
    "        'mountain': 'mtn',\n",
    "        'expressway': 'expy',\n",
    "        'falls': 'fls',\n",
    "        'grove': 'grv',\n",
    "        'harbor': 'hbr',\n",
    "        'hill': 'hl',\n",
    "        'loop': 'loop',\n",
    "        'ridge': 'rdg',\n",
    "        'trail': 'trl',\n",
    "        'tunnel': 'tunl',\n",
    "        'valley': 'vly',\n",
    "        'extension': 'ext',\n",
    "    }\n",
    "\n",
    "    for k, v in replacements.items():\n",
    "        df['add'] = df['add'].str.replace(r'\\b' + k + r'\\b', v, regex=True)\n",
    "\n",
    "    # Remove non-digits from 'zip'\n",
    "    df['zip'] = df['zip'].str.replace('\\D','',regex=True)\n",
    "\n",
    "    # Lowercase, remove non-alphabetical characters and ' county' in 'county'\n",
    "    df['county'] = df['county'].str.lower().str.replace('[^a-z ]','', regex=True).str.replace(' county','', regex=True)\n",
    "\n",
    "    # Lowercase, remove non-alphabetical characters and ' city' in 'city'\n",
    "    df['city'] = df['city'].str.lower().str.replace('[^a-z ]','', regex=True).str.replace(' city','', regex=True)\n",
    "\n",
    "    # Replace empty fields or fields with placeholder values with NaN\n",
    "    fields = ['fname','mname','lname','dob','phone','email','add','zip','county','city']\n",
    "    for field in fields:\n",
    "        df[field] = df[field].apply(lambda x: np.nan if ((len(str(x).strip()) == 0)|(str(x).lower().strip() in ['none','na','missing','unknown'])) else x)\n",
    "\n",
    "\n",
    "    # Generate metaphone versions of the fields\n",
    "    for col in ['fname', 'lname']:\n",
    "        df['meta_'+col] = phonetic(df[col], method='metaphone')\n",
    "        df['sdx_'+col] = phonetic(df[col], method='soundex')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to map\n",
    "mapping_cols = {\n",
    "    'new__first_name': 'fname',\n",
    "    'new__middle_name': 'mname',\n",
    "    'new__last_name': 'lname',\n",
    "    'new__dob': 'dob',\n",
    "    'new__sex_at_birth': 'sex',\n",
    "    'new__phone': 'phone',\n",
    "    'new__email': 'email',\n",
    "    'new__address': 'add',\n",
    "    'new__zip': 'zip',\n",
    "    'new__county_name': 'county',\n",
    "    'new__city': 'city',\n",
    "    'new__state': 'state'\n",
    "}\n",
    "\n",
    "# Standardize the columns using custom function\n",
    "df_standardized = standardize_columns(df, mapping_columns=mapping_cols, extra_columns=['unique_id'])\n",
    "\n",
    "# Apply preprocessing\n",
    "df_preprocessed = apply_preprocessing(df_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.to_parquet('../../Data/Training/03. Preprocessed Data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
