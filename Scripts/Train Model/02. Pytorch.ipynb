{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "---------\n",
    "\n",
    "### Author Information\n",
    "**Author:** PJ Gibson  \n",
    "**Email:** Peter.Gibson@doh.wa.gov  \n",
    "**Github:**   https://github.com/DOH-PJG1303\n",
    "\n",
    "### Project Information\n",
    "**Created Date:** 2023-08-09  \n",
    "**Last Updated:** 2023-08-09  \n",
    "**Version:** 1  \n",
    "\n",
    "### Description\n",
    "\n",
    "In this notebook, we train a ML model for record linkage.\n",
    "We'll use PyTorch.\n",
    "\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "*\\*If you are unfamiliar with the origins of this synthetic data, please see the [Synthetic-Gold](https://github.com/DOH-PJG1303/Synthetic-Gold) github project. We ran the simulation for the state of Nebraska, so all data is relevant to that state.\n",
    "To manage the size of the data we'll have publicly stored on Github, we only captured relevant data for each table for the population living in years 2019-2022*\n",
    "\n",
    "\n",
    "*\\*\\*Annotation improved with the help of chat-GPT*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2492bf3deb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for code reproducibility\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prep Data\n",
    "\n",
    "### 2.1 Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../Data/Training/04. Training Data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('label',axis=1), df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow\n",
    "\n",
    "### 3.1 Conversion\n",
    "\n",
    "Can't have it resting as a pandas dataframe.\n",
    "Needs to be tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas DataFrames to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values.astype('float32'))\n",
    "y_train_tensor = torch.tensor(y_train.values.astype('float32'))\n",
    "X_test_tensor = torch.tensor(X_test.values.astype('float32'))\n",
    "y_test_tensor = torch.tensor(y_test.values.astype('float32'))\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders (you can adjust the batch_size and shuffle as needed)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define Param Grid Search Space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    [(64,), (100, 50), (30, 20, 10), (50, 50, 50), (10, 10, 10, 10)], # Hidden dimensions\n",
    "    [0.1, 0.01, 0.001],                                               # Learning rates\n",
    "    [5, 10, 20],                                                      # Number of epochs\n",
    "    ['Adam', 'SGD', 'RMSprop']                                        # Optimizers\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model Wrapping/Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"A wrapper class for PyTorch models that implements the mlflow.pyfunc.PythonModel interface.\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, context, model_input):\n",
    "        with torch.no_grad():\n",
    "            model_input_tensor = torch.tensor(model_input.values, dtype=torch.float32)\n",
    "            output = self.model(model_input_tensor)\n",
    "            return output.numpy()[:, 0]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        previous_dim = input_dim\n",
    "        for dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(previous_dim, dim),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "            previous_dim = dim\n",
    "        layers.append(nn.Linear(previous_dim, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 MLFlow config\n",
    "\n",
    "### 4.1 Create Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/pjg1303/Documents2/Python-Record-Linkage/Scripts/Train%20Model/mlruns/395511990306693902', creation_time=1692032458330, experiment_id='395511990306693902', last_update_time=1692032458330, lifecycle_stage='active', name='Record Linkage ML Model Training', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define experiment name\n",
    "experiment_name = 'Record Linkage ML Model Training'\n",
    "\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Set the experiment ID\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Define Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming it Iter1 (Iteration 1), 12 linking fields (to capture number raw data fields required)\n",
    "# [fname, mname, lname, dob, sex, add, zip, city, county, state, phone, email]\n",
    "run_name = 'Iter1, 12 linking fields'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Log Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(y_test, pred_proba_test):\n",
    "    \"\"\"Log various performance metrics.\"\"\"\n",
    "\n",
    "    test_auc_score = roc_auc_score(y_test, pred_proba_test)\n",
    "    mlflow.log_metric('auc', test_auc_score)\n",
    "    predict_binary_test = (pred_proba_test > 0.5).astype(int)\n",
    "    test_f1_score = f1_score(y_test, predict_binary_test)\n",
    "    mlflow.log_metric('f1', test_f1_score)\n",
    "    test_accuracy = accuracy_score(y_test, predict_binary_test)\n",
    "    mlflow.log_metric('accuracy', test_accuracy)\n",
    "    test_precision = precision_score(y_test, predict_binary_test)\n",
    "    mlflow.log_metric('precision', test_precision)\n",
    "    test_recall = recall_score(y_test, predict_binary_test)\n",
    "    mlflow.log_metric('recall', test_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Set Optimizer Function\n",
    "\n",
    "Mostly here for readability when called on by perform_run() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_optimizer(optimizer_name, parameters, lr):\n",
    "    optimizers = {\n",
    "        'Adam': lambda: Adam(parameters, lr=lr),\n",
    "        'SGD': lambda: SGD(parameters, lr=lr),\n",
    "        'RMSprop': lambda: RMSprop(parameters, lr=lr)\n",
    "    }\n",
    "    optimizer_func = optimizers.get(optimizer_name)\n",
    "    if optimizer_func is None:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "    return optimizer_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_run(run_name, param_grid, n_runs, train_loader, test_loader):\n",
    "    input_size = train_loader.dataset.tensors[0].size(1)\n",
    "    mlflow.pytorch.autolog()\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        hidden_dims, lr, epochs, optimizer_name = [random.choice(param) for param in param_grid]\n",
    "\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            mlflow.log_param('Model Type', 'Pytorch-MLPClassifier')\n",
    "            mlflow.log_param('learning_rate', lr)\n",
    "            mlflow.log_param('hidden_layer_sizes', str(hidden_dims))\n",
    "            mlflow.log_param('optimizer', optimizer_name)\n",
    "            mlflow.log_param('epochs', epochs)\n",
    "\n",
    "            model = MLP(input_size, hidden_dims)\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            optimizer = select_optimizer(optimizer_name, model.parameters(), lr)\n",
    "\n",
    "            # Training\n",
    "            start_fit_time = time.time()\n",
    "            for epoch in range(epochs):\n",
    "                for batch_X, batch_y in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = criterion(outputs.squeeze(), batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            fit_time = time.time() - start_fit_time\n",
    "            mlflow.log_metric('fit_time', fit_time) # Logging training time\n",
    "\n",
    "            # Testing and logging metrics\n",
    "            start_predict_time = time.time()\n",
    "            pred_proba_test = []\n",
    "            with torch.no_grad():\n",
    "                for batch_X, _ in test_loader:\n",
    "                    outputs = model(batch_X)\n",
    "                    pred_proba_test.extend(torch.sigmoid(outputs.squeeze()).numpy())\n",
    "            predict_time = time.time() - start_predict_time\n",
    "            mlflow.log_metric('predict_time', predict_time) # Logging prediction time\n",
    "\n",
    "            pred_proba_test = np.array(pred_proba_test)\n",
    "            log_metrics(test_loader.dataset.tensors[1].numpy(), pred_proba_test)\n",
    "\n",
    "            # Logging model to MLflow\n",
    "            mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/15 16:30:26 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "c:\\Users\\pjg1303\\Documents2\\Python-Record-Linkage\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pjg1303\\Documents2\\Python-Record-Linkage\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pjg1303\\Documents2\\Python-Record-Linkage\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pjg1303\\Documents2\\Python-Record-Linkage\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\pjg1303\\Documents2\\Python-Record-Linkage\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define how many runs we want.  Do not exceed number of combinations of param_grid for repetition's sake\n",
    "n_runs = 50\n",
    "\n",
    "# Perform the runs!\n",
    "perform_run(run_name, param_grid, n_runs, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Inspect Output\n",
    "\n",
    "Open a CMD terminal.  Navigate to this directory. If you're starting in the root repo folder, this will look like:\n",
    "\n",
    "```cmd\n",
    "cd \"Scripts\\Train Model\"\n",
    "```\n",
    "\n",
    "Then navigate into the MLFlow UI by typing:\n",
    "\n",
    "```cmd\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "There you can interact with models, compare different models, and select one to register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name2 = 'Iter2, 12 linking fields'\n",
    "\n",
    "param_grid2 = [\n",
    "    [(200,), (100, 100, 100), (50, 50, 50), (10, 10, 10, 10, 10)], # Hidden dimensions\n",
    "    [0.005, 0.001, 0.0005],                                               # Learning rates\n",
    "    [5, 10, 20],                                                      # Number of epochs\n",
    "    ['Adam', 'RMSprop']                                        # Optimizers\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/16 14:27:50 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "c:\\Users\\pjg1303\\Documents2\\Python-Record-Linkage\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define how many runs we want.  Do not exceed number of combinations of param_grid for repetition's sake\n",
    "n_runs = 50\n",
    "\n",
    "# Perform the runs!\n",
    "perform_run(run_name2, param_grid2, n_runs, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
